{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Programming and Big-Data\n",
    "\n",
    "- This notebook contains a very accelerated summary of the basics of python. If this is challenging, please refer to the textbook sections.\n",
    "- Being able to successfully run this also means you have a working Python environment! You now have installed everything you need to run this course.\n",
    "\n",
    "\n",
    "## Python Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments: The hashtag makes the rest of the line a comment. The more programming you do, the more you focus on making good comments.\n",
    "# Jupyter lets you write formatted text, but you'll still want to put comments in the raw python.\n",
    "\n",
    "# Assign some text (a string) to a variable\n",
    "some_text = 'This is the text.'\n",
    "\n",
    "# Assign some numbers to variables\n",
    "a = 5  # Here, we implicitly told python that a is an integer\n",
    "b = 4.6  # Here, we told python that b is a floating point number (a decimal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Even though nothing is outputted above, our Python \"Kernel\" has the values to each variable stored for later use.\n",
    "\n",
    "### Important note: Python is not a \"typed\" language\n",
    "\n",
    "- Notice that above, we added an integer and the float (a floating point number, i.e., one with a decimal point). Python \"smartly\" redefines variables so that they work together.\n",
    "\n",
    "- This is different from other languages which require you to manually manage the \"types\" of your variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our output was 9.6\n"
     ]
    }
   ],
   "source": [
    "# Python as a calculator. \n",
    "sum_of_two_numbers = a + b\n",
    "# Printing output to the console\n",
    "print('Our output was', sum_of_two_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the above, you'll notice the result was a float.\n",
    "- If needed, you can demand that python specify something as a certain type, as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We lost some precision in this operation: 9.0\n"
     ]
    }
   ],
   "source": [
    "sum_as_int = int(sum_of_two_numbers)\n",
    "sum_as_int_back_to_float = float(sum_as_int)\n",
    "\n",
    "print('We lost some precision in this operation:', sum_as_int_back_to_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Functions\n",
    "def my_function(input_parameter_1, input_parameter_2):\n",
    "    product = input_parameter_1 * input_parameter_2\n",
    "    return product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a small numpy array\n",
      " [[3 4 5]\n",
      " [5 7 4]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Built-in packages via the Python Standard Library\n",
    "import math\n",
    "import os, sys, time, random\n",
    "\n",
    "# Using imported modules\n",
    "number_rounded_down = math.floor(sum_of_two_numbers)\n",
    "\n",
    "# NOTE: From here on, output print statements will start with a comment (to deactivate them) so that your output isn't overwhelming.\n",
    "# but you can uncomment to view it.\n",
    "\n",
    "# print(number_rounded_down)\n",
    "\n",
    "# Using packages from elsewhere\n",
    "\n",
    "# To get a new package from the internet, for example \"numpy\", simply go to\n",
    "# the command line/terminal (Not this python editor, but the actual command line, which conveniently is\n",
    "# provided in the \"Terminal\" tab in PyCharm below). In the command line, simply type\n",
    "# \"pip install numpy\". Now numpy can be imported:\n",
    "\n",
    "import numpy as np # The as just defines a shorter name\n",
    "\n",
    "# Create an 2 by 3 array of random integer\n",
    "low = 3\n",
    "high = 8\n",
    "size = (2, 3)\n",
    "small_array = np.random.randint(low, high, size)\n",
    "print('Here\\'s a small numpy array\\n', small_array)\n",
    "\n",
    "# Sidenote: from above backspace \\ put in front of a character is the\n",
    "# \"escapce character,\" which makes python interpret the next thing as a string or special text operator. \\n makes a line break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a geotiff as a raster\n",
    "\n",
    "The workhorse library at the heart of open-source earth analytics is GDAL (Geospatial Data Abstraction Library). It can read almost any spatial raster type. We're going to use it to load a raster from Johnson et al. 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['assignment_06.zip', 'Production_Crops_E_All_Data_(Normalized).zip', 'gtap_invest', 'assignment_5', 'ESACCI-LC-L4-LCCS-Map-300m-P1Y-2010-v2.0.7.tif', 'ESACCI-LC-L4-LCCS-Map-300m-P1Y-2010-v2.0.7.tif.aux.xml', 'ESACCI-LC-L4-LCCS-Map-300m-P1Y-2010-v2.0.7.tif.ovr', 'ESACCI-LC-L4-LCCS-Map-300m-P1Y-2015-v2.0.7.tif', 'ESACCI-LC-L4-LCCS-Map-300m-P1Y-2015-v2.0.7.tif.aux.xml', 'ESACCI-LC-L4-LCCS-Map-300m-P1Y-2015-v2.0.7.tif.ovr', 'landsat.zip', 'maize_HarvAreaYield_Geotiff.zip', 'maize_HarvestedAreaFraction.tif', 'maize_HarvestedAreaFraction.tif.aux.xml', 'maize_HarvestedAreaFraction.tif.ovr', 'maize_HarvestedAreaHectares.tif', 'maize_HarvestedAreaHectares.tif.aux.xml', 'maize_HarvestedAreaHectares.tif.ovr', 'maize_Production.tif', 'maize_Production.tif.aux.xml', 'maize_Production.tif.ovr', 'maize_YieldPerHectare.tif', 'maize_YieldPerHectare.tif.aux.xml', 'maize_YieldPerHectare.tif.ovr', 'MN-geospatial.zip', 'ne_110m_admin_0_countries.cpg', 'ne_110m_admin_0_countries.dbf', 'ne_110m_admin_0_countries.prj', 'ne_110m_admin_0_countries.README.html', 'ne_110m_admin_0_countries.shp', 'ne_110m_admin_0_countries.shx', 'ne_110m_admin_0_countries.VERSION.txt', 'ParcelsCarver.zip', 'Production_Crops_E_All_Data_(Normalized).csv', 'rwanda_lulc_2000.tif', 'rwanda_lulc_2000.tif.aux.xml', 'rwanda_lulc_2010.tif', 'rwanda_lulc_2010.tif.aux.xml', 'rwanda_lulc_2015.tif', 'rwanda_lulc_2015.tif.aux.xml', 'WDI_CO2_data.csv', 'world_monthly_food_prices.csv', 'crop_nutrient_data.csv', 'crop_production_tons_per_cell.tif', 'crop_production_tons_per_cell.tif.aux.xml', 'crop_production_tons_per_cell.tif.ovr', 'Data_Extract_From_World_Development_Indicators.zip', 'ESACCI-LC-L4-LCCS-Map-300m-P1Y-2000-v2.0.7.tif', 'ESACCI-LC-L4-LCCS-Map-300m-P1Y-2000-v2.0.7.tif.aux.xml', 'ESACCI-LC-L4-LCCS-Map-300m-P1Y-2000-v2.0.7.tif.ovr']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load a geotiff as a numpy array using GDAL\n",
    "\n",
    "from osgeo import gdal\n",
    "geotiff_filename = 'crop_production_tons_per_cell.tif'\n",
    "directory = '../../../Data'\n",
    "geotiff_filename = os.path.join('../../../Data', 'crop_production_tons_per_cell.tif')\n",
    "contents = os.listdir(directory)\n",
    "print(contents)\n",
    "\n",
    "# First, open the gdal dataset\n",
    "carbon_conserved_dataset = gdal.Open(geotiff_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The dataset object holds information about the area and extent of the data, or the geotransform information\n",
    "geotransform = carbon_conserved_dataset.GetGeoTransform()\n",
    "projection = carbon_conserved_dataset.GetProjection()\n",
    "# print('GDAL dataset geotransform', geotransform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'world_monthly_food_prices.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 83\u001b[0m\n\u001b[0;32m     79\u001b[0m output_band\u001b[39m.\u001b[39mSetNoDataValue(no_data_value)\n\u001b[0;32m     81\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m food_prices \u001b[39m=\u001b[39m pandas\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mworld_monthly_food_prices.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     84\u001b[0m \u001b[39m# print('Whole dataframe:', food_prices)\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[39m# print('List of column names:', food_prices.columns)\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[39m# print('Specific column:', food_prices['Value'])\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[39m# print('Specific value in that column:', food_prices['Value'][6])\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jajohns\\AppData\\Local\\mambaforge\\envs\\8222env1\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jajohns\\AppData\\Local\\mambaforge\\envs\\8222env1\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jajohns\\AppData\\Local\\mambaforge\\envs\\8222env1\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\jajohns\\AppData\\Local\\mambaforge\\envs\\8222env1\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\jajohns\\AppData\\Local\\mambaforge\\envs\\8222env1\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\jajohns\\AppData\\Local\\mambaforge\\envs\\8222env1\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\jajohns\\AppData\\Local\\mambaforge\\envs\\8222env1\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'world_monthly_food_prices.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# IMPORTANT ANNOYING NOTE: in programming, there are different conventions for identifying a place by rows, cols vs. x, y vs. upper-left, lower-right, etc.\n",
    "# Numpy is denoted row, col but gdal is denoted X, Y (which flips the order). Just memorize that row = Y and col = X.\n",
    "\n",
    "n_rows = carbon_conserved_dataset.RasterYSize\n",
    "#print('Number of rows in a GDAL dataset', n_rows)\n",
    "\n",
    "n_cols = carbon_conserved_dataset.RasterXSize\n",
    "#print('Number of columns in a GDAL dataset', n_cols)\n",
    "\n",
    "# Next, get the \"band\" of the dataset. Many datasets have multiple layers (e.g. NetCDFs).\n",
    "# Geotiffs only have 1 band by default, so we just grab band 1\n",
    "carbon_conserved_band = carbon_conserved_dataset.GetRasterBand(1)\n",
    "\n",
    "# The band object has information too, like the datatype of the geotiff:\n",
    "data_type = carbon_conserved_band.DataType\n",
    "no_data_value = carbon_conserved_band.GetNoDataValue()\n",
    "\n",
    "# Finally, we can get the array from the band as a numpy array:\n",
    "c = carbon_conserved_band.ReadAsArray()\n",
    "shape = c.shape\n",
    "\n",
    "# print('Look at the array itself', c)\n",
    "# print('Add up the array', np.sum(c))\n",
    "\n",
    "# Make a copy in memory for us to play with. NOTE that if we just did c_view = c and then modified c_view, the c array would also be changed.\n",
    "c_view = c # This only creates a new pointer to the same block of memory on your computer that holds the array. If we change c_view, c will also be changed.\n",
    "c_calcs = c.copy() # This gives us a NEW array in a new block of memory, so changing c_calcs will not change c.\n",
    "\n",
    "# Get specific elements in the array with [row, col]\n",
    "specific_value = c_calcs[400, 500]\n",
    "\n",
    "# Or you can get values between a range of rows and cols with :\n",
    "chunk_of_array = c_calcs[1000:1100, 1600:1700] # This would give you a 100 by 100 subarray\n",
    "\n",
    "# Or you can select out a subset of the array based on a logic conditional\n",
    "conditional_subset = c_calcs[c_calcs>10000]\n",
    "\n",
    "# Note that when we took the conditional subset, the array dimensions no longer made sense (there now are unspecified missing locations).\n",
    "# Numpy deals with this by flattening the array to 1 dimension.\n",
    "#print('conditional_subset shape', conditional_subset.shape)\n",
    "\n",
    "# But, if we don't save it as a new array (and do something like reassigning values), it retains the array's shape.\n",
    "# print('Sum of c_calcs before changing values', np.sum(c_calcs))\n",
    "\n",
    "# Change all values in c_calcs that are > 10000 to 22 IN-PLACE (i.e., changes the underlying c_calcs array).\n",
    "c_calcs[c_calcs>10000] = 22\n",
    "# print('Sum of c_calcs after changing values', np.sum(c_calcs))\n",
    "\n",
    "# Set c_calcs back to the original by taking a new copy\n",
    "c_calcs = c.copy()\n",
    "\n",
    "# If you dont want to overwrite c_calcs, the above method won't work unless you create another copy first.\n",
    "d = c_calcs.copy()\n",
    "\n",
    "d[(d > 200) & (d < 10000)] = 33 # Note, unlike vanilla python, Numpy conditionals here must use & and must be in parenthases.\n",
    "# print('The sum of d after we messed with it', np.sum(d))\n",
    "\n",
    "# Save the as a new geotiff to disk\n",
    "\n",
    "# Create a new filename for our output file. The + concatenates things. Str() makes the number a string.\n",
    "# This is one of those cases where python wouldn't correctly guess the data type\n",
    "output_filename = 'gdal_created_array_' + str(random.randint(1, 1000000)) + '.tif'\n",
    "\n",
    "# Create a new file at that filename location using the attributes we used above\n",
    "# Notice that we flipped n_cols and n_rows from how numpy would have wanted it.\n",
    "output_dataset = gdal.GetDriverByName('GTiff').Create(output_filename, n_cols, n_rows, 1, data_type)\n",
    "\n",
    "# Set dataset-level information\n",
    "output_dataset.SetGeoTransform(geotransform)\n",
    "output_dataset.SetProjection(projection)\n",
    "\n",
    "# Now get a band from our new dataset on which we'll write our array.\n",
    "output_band = output_dataset.GetRasterBand(1)\n",
    "\n",
    "# Do the array writing\n",
    "output_band.WriteArray(d)\n",
    "\n",
    "# Set any final band-level information\n",
    "output_band.SetNoDataValue(no_data_value)\n",
    "\n",
    "import pandas\n",
    "\n",
    "food_prices = pandas.read_csv('world_monthly_food_prices.csv')\n",
    "# print('Whole dataframe:', food_prices)\n",
    "# print('List of column names:', food_prices.columns)\n",
    "# print('Specific column:', food_prices['Value'])\n",
    "# print('Specific value in that column:', food_prices['Value'][6])\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "# plt.plot(food_prices['Value'])\n",
    "# plt.show()\n",
    "#\n",
    "# plt.imshow(c)\n",
    "# plt.show()\n",
    "\n",
    "# Sightly more complex example\n",
    "# Create a new figure and axes.\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Make up some data\n",
    "data = np.clip(np.random.randn(250, 250), -1, 1)\n",
    "\n",
    "# Use the axes object to show the data with a coolwarm colorbar\n",
    "cax = ax.imshow(data, interpolation='nearest', cmap=matplotlib.cm.coolwarm)\n",
    "\n",
    "# Give a title to the axis.\n",
    "ax.set_title('Gaussian noise with vertical colorbar')\n",
    "\n",
    "# Add a colorbar to  the figure\n",
    "cbar = fig.colorbar(cax, ticks=[-1, 0, 1]) # Add colorbar, make sure to specify tick locations to match desired ticklabels\n",
    "\n",
    "# Modify the axes within the colorbar\n",
    "cbar.ax.set_yticklabels(['< -1', '0', '> 1'])  # vertically oriented colorbar\n",
    "\n",
    "# Show it.\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('8222env1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0db313e0ad7b6749a6d098fb61fddaded88cbd823278030b75fa0893942c8f77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
